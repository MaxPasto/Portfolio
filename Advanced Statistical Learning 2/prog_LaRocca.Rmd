---
title: "Advanced Statistical Learning 2 - Vehicle dataset"
author: "Massimiliano Pastorino"
output:
  html_document:
    df_print: paged
  pdf_document: default
---

```{r setup, include=FALSE, warning=FALSE}
knitr::opts_chunk$set(root.dir = 'C:/Users/massi/OneDrive/Desktop/Progetto-LaRocca', echo = FALSE)
```

# Introduzione

Il caso studio in esame riguarda l'analisi del dataset "Vehicle dataset" reperibile al seguente link: https://www.kaggle.com/datasets/nehalbirla/vehicle-dataset-from-cardekho?select=Car+details+v3.csv. Lo scopo è quello di prevedere il prezzo di vendita di auto usate sulla base di una serie di variabili sia di tipo numerico sia di tipo categoriale. L'obiettivo è quello di creare una rete neurale in grado di prevedere al meglio il prezzo delle auto usate e soprattutto cogliere le relazioni non lineari esistenti tra la variabile dipendente y (prezzo di vendita in euro) e le variabili indipendenti (x). In questo caso studio la rete neurale implementata verrà confrontata con una sorta di modello benchmark iniziale che in questo caso è rappresentato dalla regressione lineare, un modello meno complesso che in alcuni casi basta per descrivere la relazione tra y ed x e che è molto utile in quanto non si segue l'approccio black-box tipico delle reti neurali in cui l'obiettivo cardine è solo prevdere al meglio la variabile dipendente y. La libreria utilizzata per la costruzione della rete neurale è la libreira nnet. Il dataset utilizzato è stato ripulito in modo tale da non avere righe duplicate, valori mancanti e variabili non correttamente formattate.



```{r, include=FALSE, warning=FALSE, message=FALSE}
library(ggplot2)
library(dplyr)
library(readr)

Car_details_v3 <- read_csv("C:/Users/massi/OneDrive/Desktop/Progetto-LaRocca/Car details v3.csv", show_col_types = FALSE)

## Data cleaning

car <- Car_details_v3

View(car)

car$name <- NULL

car$torque <- NULL

car$year <- NULL

## ci sono valori mancanti ?

table(is.na(car))

## tolgo i valori mancanti

car <- na.omit(car)

table(is.na(car)) 

dim(car) ## 7906 x 12 

## ci sono righe duplicate ? 

car <- car[!duplicated(car), ]

dim(car) ## 6698 x 12 (1208 righe duplicate)

## struttura del data set

glimpse(car)

## NOTA (selling_price è espresso in RUPIE INDIANE)

## Convertiamo le rupe indiane in euro -> selling_price * 0.011

car$selling_price <- round( (car$selling_price * 0.011) ,1)

## fuel -> Trasformiamo fuel in fattore

car$fuel <- factor(car$fuel)

table(car$fuel)

levels(car$fuel)

## seller_type -> Trasformiamo seller_type in fattore

car$seller_type <- factor(car$seller_type)

table(car$seller_type)

levels(car$seller_type)

## transmission ->  Trasformiamo transmission in fattore

car$transmission <- factor(car$transmission)

table(car$transmission)

levels(car$transmission)

## owner  -> Trasformiamo owner in fattore

car$owner <- factor(car$owner)

table(car$owner)

levels(car$owner)

## mileage -> Presenta due unità di misure differenti, uno kmpl e l'altro km/kg

idx_km_kg <- which(grepl(' km/kg', car$mileage)) ## indici in cui è presente lo spazio + km/kg

car$mileage[idx_km_kg] ## visualizzo

## tolgo lo spazio + km/kg

gsub(' km/kg','',car$mileage[idx_km_kg])

## trasformo in double e moltiplico x 1.40 per la conversione da km/kg a kmpl

car$mileage[idx_km_kg] <- as.double(gsub(' km/kg','',car$mileage[idx_km_kg])) * 1.40

## tolgo lo spazio + kmpl

car$mileage[-idx_km_kg] ## visualizzo


car$mileage[-idx_km_kg] <- as.double(gsub(' kmpl','',car$mileage[-idx_km_kg]))

## engine (cilindrata) -> Trasformo engine in double

## Rimuovo CC e trasformo in double

car$engine <- as.double((gsub(' CC','',car$engine)))

## max power -> Trasformo maxpower in double

## Rimuovo bhp e trasformo in double

car$max_power <- as.double((gsub(' bhp','',car$max_power)))

## NOTA

table(is.na(car$max_power)) ## C'è un NA

## Indice

which(is.na(car$max_power)) ## 4113

car$max_power[4113] ## NA -> rimuovo questa riga

car <- car[-4113,]

## Ricontrollo la struttura finale

str(car)

car$mileage <- as.double(car$mileage) 

## Problema di regressione, la variabile dipendente è: selling_price

## selling_price indica il prezzo a cui l'auto è stata venduta


# write.csv(car, file = "clean_car.csv")

## Fine Data Cleaning
```

```{r,echo=FALSE, warning=FALSE, message=FALSE}
## Elimino i valori più anomali

Quantile1 <- quantile(car$selling_price, probs=.25)

Quantile3 <- quantile(car$selling_price, probs=.75)
 
# calculate inter quartile range

IQR = Quantile3-Quantile1
 
# return true or false
idx <- which(car$selling_price > Quantile3 + (IQR*1.5) | car$selling_price < Quantile1 - (IQR*1.5))
    
car <- car[-idx,]


Quantile1 <- quantile(car$km_driven, probs=.25)

Quantile3 <- quantile(car$km_driven, probs=.75)
 
# calculate inter quartile range

IQR = Quantile3-Quantile1
 
# return true or false
idx <- which(car$km_driven > Quantile3 + (IQR*1.5) | car$km_driven < Quantile1 - (IQR*1.5))
car <- car[-idx,]



Quantile1 <- quantile(car$mileage, probs=.25)

Quantile3 <- quantile(car$mileage, probs=.75)
 
# calculate inter quartile range

IQR = Quantile3-Quantile1
 
# return true or false
idx <- which(car$mileage > Quantile3 + (IQR*1.5) | car$mileage < Quantile1 - (IQR*1.5))
car <- car[-idx,]


Quantile1 <- quantile(car$max_power, probs=.25)

Quantile3 <- quantile(car$max_power, probs=.75)
 
# calculate inter quartile range

IQR = Quantile3-Quantile1
 
# return true or false
idx <- which(car$max_power > Quantile3 + (IQR*1.5) | car$max_power < Quantile1 - (IQR*1.5))
car <- car[-idx,]


Quantile1 <- quantile(car$engine, probs=.25)

Quantile3 <- quantile(car$engine, probs=.75)
 
# calculate inter quartile range

IQR = Quantile3-Quantile1
 
# return true or false
idx <- which(car$engine > Quantile3 + (IQR*1.5) | car$engine < Quantile1 - (IQR*1.5))
car <- car[-idx,]

```


```{r}
## Dato che ho eliminato i valori anomali controllo di nuovo con un table i vari livelli
# table(car$fuel) ## ok 
# table(car$transmission) ## ok
# table(car$owner) # no -> Un livello è 0 -> Test Drive Car
car$owner <- droplevels(car$owner) ## Tolgo Test Drive Car
```









# Analisi esplorativa dei dati  (EDA)

La variabile dipendente selling_price è di tipo numerico quindi è bene vedere come essa si distribuisce grazie ad un'istogramma. Dall'istogramma notiamo che il prezzo medio delle auto vendute si aggira intorno a 4646 euro e che la distribuzione è asimmetrica positiva, la maggioranza delle auto usate presenta prezzi di vendita non molto elevati.

```{r, echo=FALSE, warning=FALSE, message=FALSE}
## Inizio Analisi Esplorativa-Descrittiva di car

## Variabile dipendente -> selling_price

## Primo grafico: Plotto la variabile selling_price completa


media_selling_price <- round(mean(car$selling_price), 0)

hist_1 <- ggplot(car, aes(x = selling_price)) +
  geom_histogram() + 
  geom_segment(
    x = media_selling_price, xend = media_selling_price,
    y = 0, yend = max(car$selling_price),
    color = "red", lwd=1
  ) +
  geom_text(
    x = 6000, y = 400,
    label = paste("Media:\t", media_selling_price,"€"),
    color = "red"
  ) + theme_bw() + xlab("Prezzo di vendita in euro") + ylab("Frequenza Assoluta") + ggtitle("Distribuzione dei prezzi di vendita") + geom_density()
  
  
  
## Secondo grafico: Con il metodo dei percentili, 

## tutte le osservazioni che si trovano al di fuori dell'intervallo formato 

## dai percentili 2,5 e 97,5 saranno considerate come potenziali outlier.

# media_selling_price_senzaOutlier <- round(mean(car[-outlier_ind,]$selling_price), 0)


hist_1
```

Dato che nel dataset in esame sono presenti molte variabile numeriche, è utile individuare eventuali legami lineari e quindi osservare la correlazione per capire quanto è intenso tale legame lineare se presente. Ad esempio come possiamo vedere dal grafico, il prezzo di vendita è correlato negativamente con il numero di chilometri percorsi, mentre è correlato positivamente con il numero di posti auto e massima potenza del motore. All'aumentare della potenza del motore, aumenta anche il prezzo di vendita, cosi come per il numero di posti all'interno dell'auto. All'aumentare dei chilometri percorsi il prezzo di vendita diminuisce. Il legame lineare più intenso è tra engine e max_power, pari a 0.8


```{r, echo=FALSE, warning=FALSE, message=FALSE}
GGally::ggpairs(car %>% dplyr::select(selling_price, km_driven, mileage, engine, max_power, seats))
```



Infine, prima di concludere l'analisi esplorativa, è utile selezionare le variabili categoriali presenti nel dataset per vedere come esse incidono sul prezzo di vendita.

Le auto a benzina e diesel presentano un prezzo di vendita mediano maggiore cosi come le auto con un cambio automatico.

```{r,echo=FALSE, warning=FALSE, message=FALSE}
# gridExtra::grid.arrange(hist_1, hist_2)

## Commento la differenza tra i due grafici 

## Terzo grafico: ggpairs con variabili numeriche


variabili_categoriali <- car %>% dplyr::select(selling_price, where(is.factor))

carburante <- ggplot(variabili_categoriali, aes(x = fuel, y = selling_price)) + 
  geom_boxplot() + coord_flip() + xlab("Tipo di carburante") + 
  ylab("Prezzo di vendita in euro") +
  ggtitle("Tipo di carburante vs prezzo di vendita") +
  coord_flip() +
  theme_bw()

venditore <- ggplot(variabili_categoriali, aes(x = seller_type, y = selling_price)) + 
  geom_boxplot() + 
  coord_flip() + 
  xlab("Tipo di venditore") + 
  ylab("Prezzo di vendita in euro") +
  ggtitle("Tipo di venditore vs prezzo di vendita") +
  coord_flip() +
  theme_bw()

trasmissione <- ggplot(variabili_categoriali, aes(x = transmission, y = selling_price)) +
  geom_boxplot() +
  coord_flip() + 
  xlab("Tipo di trasmissione") + 
  ylab("Prezzo di vendita in euro") +
  ggtitle("Tipo di trasmissione vs prezzo di vendita") +
  coord_flip() +
  theme_bw()


proprietario <- ggplot(variabili_categoriali, aes(x = owner, y = selling_price)) + geom_boxplot() + 
  coord_flip() + 
  xlab("Numero di proprietari precedenti") + 
  ylab("Prezzo di vendita in euro") +
  ggtitle("Numero di proprietari precedenti vs prezzo di vendita") +
  coord_flip() +
  theme_bw()


gridExtra::grid.arrange(carburante, trasmissione)  
```

Le auto usate comprate da un rivenditore presentano un prezzo di vendita mediano maggiore. Anche il numero di proprietari precedenti influisce, infatti le auto che hanno avuto un solo proprietario precedente presentano un prezzo maggiore.


```{r,echo=FALSE, warning=FALSE, message=FALSE}

gridExtra::grid.arrange(venditore, proprietario) 
```


# Data pre-processing

In questa fase abbiamo normalizzato tutte le variabili numeriche e abbiamo applicato il one-hot encoding alle variabili categoriali.


```{r,echo=FALSE, message = FALSE, warning=FALSE}
## Data pre-processing

library(dplyr)
library(caret)
set.seed(300399)


## Data splitting for hold-out cross-validation
splittedData <- rsample::initial_split(car , prop = 3/4)

dataTrain <- rsample::training(splittedData) ## Train -> 4973 x 16

dataTest <- rsample::testing(splittedData)   ## Test ->  1658 x 16

## Primo step: Applico il one-hot encoding alle variabili categoriali

## Training-Set (Questo lo uso per la regressione lineare multipla e per la rete neurale senza weight decay, in cui dobbiamo escludere un livello)

y_xCategoriali_Train <- dataTrain %>% dplyr::select(selling_price, where(is.factor))

xCategoriali_OneHot_Train <-  as_tibble(model.matrix(selling_price ~., y_xCategoriali_Train)[,-1]) 


## Test-Set

y_xCategoriali_Test <- dataTest %>% dplyr::select(selling_price, where(is.factor))

xCategoriali_OneHot_Test <-  as_tibble(model.matrix(selling_price ~., y_xCategoriali_Test)[,-1]) 


## Secondo step: Normalizziamo le variabili numeriche (min-max)

norm_minmax <- function(x){
                           (x- min(x)) /(max(x)-min(x))
                          }

## Training-Set

x_numeriche_Train <- dataTrain[,-1]%>% dplyr::select(where(is.numeric))


x_numeriche_normalizzate_Train <- as.data.frame(lapply(x_numeriche_Train, norm_minmax))

## Test-Set

x_numeriche_Test <- dataTest[,-1] %>% dplyr::select(where(is.numeric))


x_numeriche_normalizzate_Test <- as.data.frame(lapply(x_numeriche_Test, norm_minmax))

## Terzo step: Unisco  le variabili categoriali con one-hot con le variabili numeriche normalizzate

## Training-Set

yxNormalizzate_xCategorialiOneHot_Train <- as_tibble(cbind(dataTrain[,1],x_numeriche_normalizzate_Train, xCategoriali_OneHot_Train))

## Test-Set

yxNormalizzate_xCategorialiOneHot_Test <- as_tibble(cbind(dataTest[,1],x_numeriche_normalizzate_Test, xCategoriali_OneHot_Test))

library(janitor)

yxNormalizzate_xCategorialiOneHot_Train <- clean_names(yxNormalizzate_xCategorialiOneHot_Train)


yxNormalizzate_xCategorialiOneHot_Test <- clean_names(yxNormalizzate_xCategorialiOneHot_Test)
```



```{r,echo=FALSE, message = FALSE, warning=FALSE}
library(mltools)
library(data.table)

## Primo step: Applico il one-hot encoding alle variabili categoriali

## Training-Set (Questo lo uso per la rete neurale con weight decay)

# y_xCategoriali_Train <- dataTrain %>% dplyr::select(selling_price, where(is.factor))

xCategoriali_OneHot_Train2 <-  one_hot(as.data.table(y_xCategoriali_Train[,-1]))

## Test-Set

# y_xCategoriali_Test <- dataTest %>% dplyr::select(selling_price, where(is.factor))

xCategoriali_OneHot_Test2 <-  one_hot(as.data.table(y_xCategoriali_Test[,-1]))


x_numeriche_normalizzate_Train <- as.data.frame(lapply(x_numeriche_Train, norm_minmax))

## Test-Set

x_numeriche_normalizzate_Test <- as.data.frame(lapply(x_numeriche_Test, norm_minmax))

## Terzo step: Unisco  le variabili categoriali con one-hot con le variabili numeriche normalizzate

## Training-Set
yxNormalizzate_xCategorialiOneHot_Train2 <- as_tibble(cbind(dataTrain[,1],x_numeriche_normalizzate_Train, xCategoriali_OneHot_Train2))

## Test-Set

yxNormalizzate_xCategorialiOneHot_Test2 <- as_tibble(cbind(dataTest[,1],x_numeriche_normalizzate_Test, xCategoriali_OneHot_Test2))

library(janitor)

yxNormalizzate_xCategorialiOneHot_Train2 <- clean_names(yxNormalizzate_xCategorialiOneHot_Train2)


yxNormalizzate_xCategorialiOneHot_Test2 <- clean_names(yxNormalizzate_xCategorialiOneHot_Test2)

```


```{r}
car_train_test_formattato <- 
as_tibble(rbind(yxNormalizzate_xCategorialiOneHot_Train, yxNormalizzate_xCategorialiOneHot_Test))

car_train_test_formattato[,-1]
```


# Regressione Lineare multipla

Innanzitutto dividiamo il dataset in training set e test set. Il training set è composto dall'75% delle osservazioni totali e verrà utilizzato per addestrare i vari modelli, regressione lineare e rete neurale, mentre il restante 25% farà parte del test set e verrà utilizzato per vedere quanto bene/male il modello in esame prevede il prezzo di vendita.

L'output della regressione lineare multipla mostra un Adjusted R-squared pari a 0.65, ovvero il 65% della variabilità del prezzo di vendita delle auto usate è spiegata dalle variabili
indipendenti prese in considerazione, rimane un 35% di variabilità da attribbuire ad altre variabili che non abbiamo preso in considerazione nel modello in esame.

Il p-value associato al test F è minore di 0.05, quindi rifiutiamo l'ipotesi nulla, ovvero il modello ha capacità esplicativa, almeno un $\beta_{j} \not=0$ con j=1,...,p.


Il livello di significatività del p-value associato al test T è identificato con gli *, in questo caso notiamo come la maggioranza dei regressori sia rilevante per la spiegazione della variabile dipendente considerando i vari livelli di significatività identificati.

Infine, l’interpretazione dei parametri è semplice. L’intercetta misura il livello medio del prezzo di vendita quando i valori di tutte le variabili indipendenti è nullo, mentre il singolo coefficiente associato ad una variabile esprime la variazione che subisce in media il prezzo di vendita in seguito a una variazione unitaria del regressore in esame, posto che il valore degli altri regressori rimanga costante. Con le reti neurali queste considerazioni non possono essere fatte, si segue un approccio di tipo black-box.

```{r,echo=FALSE, message=FALSE, warning=FALSE}
yxNormalizzate_xCategorialiOneHot_Train$selling_price <- norm_minmax(yxNormalizzate_xCategorialiOneHot_Train$selling_price)

yxNormalizzate_xCategorialiOneHot_Test$selling_price <- norm_minmax(yxNormalizzate_xCategorialiOneHot_Test$selling_price)

lm.fit <- lm(selling_price ~ ., data=yxNormalizzate_xCategorialiOneHot_Train[,-4])
summary(lm.fit)
```

Utilizziamo il modello di regressione lineare multiplo addestrato sui dati di training per prevedere sui dati unseen (test set) il prezzo di vendita delle auto usate. Dal grafico notiamo che il modello considerato non prevede molto bene i prezzi di vendita, soprattutto in quei casi in cui abbiamo dei prezzi di vendita osservati molto elevati.


```{r,echo=FALSE, warning=FALSE, message=FALSE}
lm.pred <- predict(lm.fit,yxNormalizzate_xCategorialiOneHot_Test[,-4])

min = min(dataTrain$selling_price) ## originali
max = max(dataTrain$selling_price) ## originali

unscale.price <- function(scaled.price){
  unscaled = scaled.price*(max-min) + min
  return(unscaled)
}


lm.pred.unscaled <- round(unscale.price(lm.pred),0)

dataTest$linearPred <- lm.pred.unscaled

ggplot(dataTest,aes(selling_price,linearPred)) +
geom_point() +
geom_abline(col="red") + theme_bw() + xlab("Prezzo di vendita") + ylab("Previsione") + ggtitle("Previsione vs Prezzo di vendita") + geom_text(
    x = 7000, y = 10000,
    label = paste("Previsione = Prezzo di vendita"),
    color = "red"
  )
```


Le metriche di performance per valutare i modelli sono le seguenti:

* RMSE: Root Mean Square Error

* MAE: Median Absolute Error

* $R^{2}$: Indice $R^{2}$

Preferiamo quei modelli che presentano un Root Mean Square Error e un Median Absolute Error
basso. Le metriche di performance del modello in esame sono riportate nella tabella seguente.


```{r,echo=FALSE, warning=FALSE, message=FALSE}
ComputeMetrics <- function(yAct,yPred){
RMSE <- sqrt(mean((yAct-yPred)^2))
MAE <- median(abs(yAct-yPred))
R2 <- (cor(yAct,yPred))^2
metrics <- c(RMSE,MAE,R2)
names(metrics) <- c("RMSE","MAE","R2")
metrics
}

perf <-rbind(round(ComputeMetrics(dataTest$selling_price,dataTest$linearPred),1))
per_dataFrame <- as.data.frame(perf)
rownames(per_dataFrame) <- paste0("REGRESSIONE LINEARE MULTIPLA")
per_dataFrame
```

Tra le varie ipotesi che riguardano il modello di regressione lineare figurano la normalità e l'omogeneità della varianza dei residui. Dal Q-Q plot i quantili osservati (reali) vengono confrontati con i quantili attesi nel caso la distribuzione fosse normale. Se i punti si dispongono lungo la retta y=x, la distribuzione dei residui
approssima bene la normale. In questo caso notiamo che i residui non si distribuiscono come una normale.

```{r,echo=FALSE, message=FALSE, warning=FALSE}
## residui_test_set -> In realtà i residui sono sul train set, qui abbiamo gli errori di previsione

residui_test_set <- dataTest$selling_price - dataTest$linearPred
qqnorm(residui_test_set, xlab="Quantili Teorici", ylab="Quantili osservati")  # qq plot dei residui
qqline(residui_test_set)  # se si aggiunge la retta
```

É sempre consigliato accompagnare una valutazione grafica con una valutazione analitica in quanto meno soggettiva. Il risultato del test di Jarque-Bera indica un p-value minore di 0.05, in questo caso possiamo dire che l'evidenza empirica è fortemente contraria all'ipotesi nulla che quindi va rifiutata, ovvero i residui non presentano una distribuzione normale.

```{r,echo=FALSE, warning=FALSE, message=FALSE}
## Test di Jarque-Bera
library(tseries)
jarque.bera.test(residui_test_set)
```


Per verificare l’ipotesi di omogeneità delle varianze dei residui, è necessario creare un grafico a dispersione. I valori stimati del prezzo di vendita si riportano sull’asse orizzontale delle x mentre sull’asse verticale delle y si indicano i valori dei residui.
Se c’è omogeneità della varianza dei residui, i punti saranno dispersi in modo simile sia nella parte sinistra che in quella destra del grafico. In questo caso notiamo la non omogeneità della varianza dei residui. I residui di un modello di regressione costruito con il metodo dei minimi quadrati (OLS) hanno per definizione sempre media zero (linea rossa trattegiata), in questo caso come possiamo vedere dal grafico, i residui non hanno  media 0.

Il grafico a dispersione tra valori predetti e residui ci permette di individuare anche i possibili outliers, ovvero i punti isolati nel grafico. I possibili outliers, quelli con i residui più grandi, possono influenzare in maniera sostanziale la capacità di adattamento del modello ai dati, soprattutto se il campione non è molto numeroso come nel nostro caso.


```{r, echo=FALSE, warning=FALSE, message=FALSE}
plot(dataTest$linearPred, residui_test_set, ylab="Residui", xlab="Valori Stimati", main = "Residui vs Valori stimati")
abline(h=0, lty=2, col="red")
```


# Rete Neurale

Per prevedere il prezzo di vendita delle auto usate possiamo addestrare una rete neurale con la libreria nnet. Utilizziamo un nodo di input per ogni predittore (in questo caso 15) e un nodo di output per la variabile dipendente. La funzione di attivazione del nodo di output è quella di tipo lineare. Costruiamo una rete neurale con un solo strato nascosto in cui abbiamo 5 neuroni e fissiamo il numero di epoche di apprendimento pari a 500. In questo primo modello il weight decay è pari a 0, quindi non introduciamo nessuna tecnica di regolarizzazione applicata ai pesi per cercare di ridurre la complessità. L'algoritmo di ottimizzazione utilizzato per aggiornare i pesi è quello BFGS( Broyden–Fletcher–Goldfarb–Shanno algorithm).

Il numero di pesi stimati è pari a 86, ovvero 5$\times$(15+2)+1.

```{r, warning=FALSE,echo=FALSE,message=FALSE}
library(tidymodels)
```



```{r,echo=FALSE, warning=FALSE, message=FALSE}
## Utilizziamo la libreria nnet
library(nnet)
set.seed(300399)
fit.nn1 <- nnet(selling_price~.,
size=5,decay=0,linout=T,
maxit=500,trace=F,Hess=F,skip=F,
data=yxNormalizzate_xCategorialiOneHot_Train)
```


```{r,echo=FALSE, warning=FALSE, message=FALSE, fig.width=10}
library(NeuralNetTools) 
par(mar = numeric(4))
plotnet(fit.nn1, pad_x = 0.3)
```


Confrontiamo le previsioni della rete neurale con le previsioni della regressione lineare multipla sia dal punto di vista grafico sia dal punto di vista delle metriche di performance.

Dal grafico notiamo che le previsioni relative ai prezzi di vendita predetti dalla rete neurale si avvicinano di più ai veri prezzi di vendita osservati. 

```{r,echo=FALSE, warning=FALSE, message=FALSE}
notlm.pred <- predict(fit.nn1,yxNormalizzate_xCategorialiOneHot_Test)

min = min(dataTrain$selling_price) ## originali
max = max(dataTrain$selling_price) ## originali

unscale.price <- function(scaled.price){
  unscaled = scaled.price*(max-min) + min
  return(unscaled)
}


notlm.pred.unscaled <- round(unscale.price(notlm.pred),0)

dataTest$notlinearPred <- notlm.pred.unscaled

ggplot(dataTest, aes(selling_price, notlinearPred, colour="REGRESSIONE CON RETE NEURALE")) +
  geom_point() + theme_bw() +  xlab("Prezzo di vendita") + ylab("Previsione") + ggtitle("Previsione vs Prezzo di vendita") +
  geom_point(x=dataTest$selling_price,y=dataTest$linearPred, aes(colour='REGRESSIONE LINEARE MULTIPLA')) +
  scale_color_manual(
    name='Modello',
    values=c('black','red')) + geom_abline(col="grey")

```

Le metriche di performance confermano quanto detto in precedenza, la regressione implementata con la rete neurale presenta delle performance migliori rispetto a quelle della regressione lineare multipla.

```{r,echo=FALSE, warning=FALSE, message=FALSE}
library(dplyr)
perf_nn <-rbind(round(ComputeMetrics(dataTest$selling_price,dataTest$notlinearPred),1))
per_dataFrame_nn <- as_tibble(perf_nn)
per_dataFrame_lm_nn <- as.data.frame(rbind(perf, perf_nn))
rownames(per_dataFrame_lm_nn) <- c("REGRESSIONE LINEARE MULTIPLA", "REGRESSIONE CON RETE NEURALE")
```


```{r,echo=FALSE, warning=FALSE, message=FALSE}
per_dataFrame_lm_nn
```

Per evitare che la rete neurale si adatti troppo ai dati di training, è utile considerare tecniche di regolarizzazione dei pesi in modo tale da evitare situazioni di overfitting. Generalmente queste tecniche prevedono l'aggiunta di un fattore dipendente dai pesi dopo l'espressione della funzione di costo. Il parametro $\lambda$ rappresenta il tasso di regolarizzazione. Una delle tecniche più utilizzate è chiamata regolarizzazione L2 perché penalizza i pesi secondo la loro norma L2, in questo caso viene utilizzata la somma dei quadrati dei pesi come funzione di regolarizzazione. I pesi elevati vengono penalizzati maggiormente, il che incoraggia il modello ad apprendere funzioni più semplici che hanno meno probabilità di adattarsi eccessivamente ai dati di addestramento.

Anche in questo caso addestriamo una rete neurale con un solo strato nascosto in cui abbiamo 5 neuroni e con un numero di epoche di apprendimento pari a 500. L'unica differenza è l'aggiunta del weight decay fissato a 0.01.

Confrontando le previsioni delle reti neurali con e senza weight decay, notiamo che le previsioni relative ai prezzi di vendita predetti da ambo le reti neurali sono molto simili tra di loro.

```{r,echo=FALSE, warning=FALSE, message=FALSE}
yxNormalizzate_xCategorialiOneHot_Train2$selling_price <- norm_minmax(yxNormalizzate_xCategorialiOneHot_Train2$selling_price)

yxNormalizzate_xCategorialiOneHot_Test2$selling_price <- norm_minmax(yxNormalizzate_xCategorialiOneHot_Test2$selling_price)

set.seed(300399)
fit.nn2 <- nnet(selling_price~.,
size=5,decay=0.01,linout=T,
maxit=500,trace=F,Hess=F,skip=F,
data=yxNormalizzate_xCategorialiOneHot_Train2)
```


```{r,echo=FALSE, warning=FALSE, message=FALSE}
notlm2.pred <- predict(fit.nn2,yxNormalizzate_xCategorialiOneHot_Test2)

unscale.price <- function(scaled.price){
  unscaled = scaled.price*(max-min) + min
  return(unscaled)
}


notlm2.pred.unscaled <- round(unscale.price(notlm2.pred),0)

dataTest$notlinearPred2 <- notlm2.pred.unscaled

ggplot(dataTest, aes(selling_price, notlinearPred2, colour="RETE NEURALE CON WD=0.01")) +
  geom_point() + theme_bw() +  xlab("Prezzo di vendita") + ylab("Previsione") + ggtitle("Previsione vs Prezzo di vendita") +
  geom_point(x=dataTest$selling_price,y=dataTest$notlinearPred, aes(colour='RETE NEURALE SENZA WD')) +
  scale_color_manual(
    name='Modello',
    values=c('black','red')) + geom_abline(col="grey")
```



Anche le metriche di performance confermano quanto detto in precedenza. Le reti neurali con e senza weight decay presentano performance molto simili, mentre il il modello di regressione lineare multiplo è quello che presenta le metriche di performance peggiori.

```{r,echo=FALSE, warning=FALSE, message=FALSE}
perf_nn2 <- rbind(round(ComputeMetrics(dataTest$selling_price,dataTest$notlinearPred2),1))

per_dataFrame_nn2 <- as_tibble(perf_nn2)

per_dataFrame_lm_nn <- rbind(per_dataFrame_lm_nn,per_dataFrame_nn2)

rownames(per_dataFrame_lm_nn) <- c("REGRESSIONE LINEARE MULTIPLA", "RETE NEURALE SENZA WD",
                                   "RETE NEURALE CON WD=0.01")

per_dataFrame_lm_nn
```

Per incrementare le performance della rete neurale possiamo pensare di implementare 
una K-fold cross-validation che è un modo popolare (ed efficace) di selezionare i parametri di ottimizzazione negli algoritmi di apprendimento statistico. Il numero di fold scelti in questo caso è pari a k=10, quindi verrà implementata una 10-Fold cross-validation. 

Gli iperparametri presi in considerazione sono:

* Numero di neuroni presenti nel singolo strato nascosto: Consideriamo una sequenza di neuroni intermedi che va da un numero minimo pari a 2 a un numero massimo pari a 10

* Weight Decay: Pari a 0.01, 0.05 e 0.1

* Numero di epoche di apprendimento: Pari a 100,500 e 1000

Per ogni combinazione degli iperparametri presi in considerazione verrà stimata una rete neurale, nel primo step, il primo fold assumerà il ruolo di test set, mentre i restanti k−1 fold svolgeranno il ruolo di training set. Il modello verrà addestrato sui k-1 fold e successivamente verrà testato sui dati unseen, che in questo caso sono rappresentati dal primo fold. La logica per gli step successivi è la medesima. Nell’ultimo step, l’ultimo fold assumerà il ruolo di test set mentre i restanti k-1 fold
svolgeranno il ruolo di training set.  Alla fine del processo avremo k metriche di performance ognuna relativa ai k step effettuati. Le k metriche di performance verranno aggregate per ottenere un’unica metrica finale. Verrà scelta quella particolare combinazione di iperparametri che garantisce il miglior root mean squared error in cross-validation.

Osservando il grafico possiamo notare come varia il root mean squared error in funzione dei 3 iperparametri considerati. Il miglior modello che presenta l'RMSE più basso in cross-validation è quello con un numero di epoche di apprendimento pari a 1000 e con un numero di neuroni intermedi pari a 10. Il weight decay selezionato è pari a 0.01.

```{r,echo=FALSE, warning=FALSE, message=FALSE}
library(tidymodels)
## definisco la griglia di iperparametri
mlp_param_nn3 <- crossing(
hidden_units = 2:14,
penalty = c(0.01,0.05, 0.1),
epochs = c(100,500,1000))
```


```{r,echo=FALSE, warning=FALSE, message=FALSE}
mlp_nn3_rec <- recipe(selling_price ~ ., data = yxNormalizzate_xCategorialiOneHot_Train2)
```


```{r,echo=FALSE, warning=FALSE, message=FALSE}
mlp_nn3_spec <-
mlp(hidden_units = tune(),
penalty = tune(),
epochs = tune()) %>%
set_engine("nnet", trace=0) %>%
set_mode("regression")
```

 
```{r,echo=FALSE, warning=FALSE, message=FALSE}
mlp_nn3_wflow <-
workflow() %>%
add_model(mlp_nn3_spec) %>%
add_recipe(mlp_nn3_rec)
```

```{r,echo=FALSE, warning=FALSE, message=FALSE}
## Calcolo parallelo, conviene dato che dobbiamo stimare tanti modelli
library("doParallel")
library("doFuture")
all_cores <- parallel::detectCores(logical = TRUE) - 1
registerDoFuture()
cl <- makeCluster(all_cores)
plan(future::cluster, workers = cl)
```


```{r,echo=FALSE, warning=FALSE, message=FALSE}
set.seed(300399)
data_folds <- vfold_cv(yxNormalizzate_xCategorialiOneHot_Train2, v = 10) # 10-fold cross-validation
```


```{r,echo=FALSE, warning=FALSE, message=FALSE}
set.seed(300399)
rmse_res <- metric_set(rmse)
mlp_reg_tune_nn3 <- mlp_nn3_wflow %>%
tune_grid(
data_folds,
grid = mlp_param_nn3,
metrics = rmse_res
)
```


```{r,echo=FALSE, warning=FALSE, message=FALSE}
autoplot(mlp_reg_tune_nn3) + theme_bw() + xlab("Numero di neuroni intermedi") + ylab("Root Mean Squared Error") + ggtitle("RMSE in base alle varie combinazioni di iperparametri")
```


```{r,echo=FALSE, warning=FALSE, message=FALSE}
bestParams <- select_best(mlp_reg_tune_nn3,metric = "rmse")
```

```{r,echo=FALSE, warning=FALSE, message=FALSE}
final_mlp_nn3_wflow <-
mlp_nn3_wflow %>%
finalize_workflow(bestParams)
```


```{r,echo=FALSE, warning=FALSE, message=FALSE}
set.seed(300399)
final_mlp_nn3_fit <-
final_mlp_nn3_wflow %>%
fit(yxNormalizzate_xCategorialiOneHot_Train2)
```

```{r,echo=FALSE, warning=FALSE, message=FALSE}
bestNet <- final_mlp_nn3_fit %>%
extract_fit_engine()
```

Il modello scelto verrà addestrato sull'intero training set, infine esso verrà utilizzato per predire i prezzi di vendita delle auto usate appartenenti al test set.

```{r,echo=FALSE, warning=FALSE, message=FALSE,fig.width=10}
library(NeuralNetTools)
par(mar = numeric(4))
plotnet(bestNet, pad_x = 0.3)
```



Confrontiamo le previsioni della rete neurale con weight decay pari 0.01 (implementata nel caso precedente, essa risulta essere la migliore finora), con la rete neurale i cui iperparametri sono stati determinati via cross-validation. 

Come possiamo notare dal grafico, le previsioni delle reti nurali considerate sono abbastanza simili.


```{r,echo=FALSE, warning=FALSE, message=FALSE}
notlm3.pred <- predict(bestNet,yxNormalizzate_xCategorialiOneHot_Test2)

unscale.price <- function(scaled.price){
  unscaled = scaled.price*(max-min) + min
  return(unscaled)
}


notlm3.pred.unscaled <- round(unscale.price(notlm3.pred),0)

dataTest$notlinearPred3 <- notlm3.pred.unscaled

ggplot(dataTest, aes(selling_price, notlinearPred3, colour="RETE NEURALE CON IPERPARAMETRI CV")) +
  geom_point() + theme_bw() +  xlab("Prezzo di vendita") + ylab("Previsione") + ggtitle("Previsione vs Prezzo di vendita") +
  geom_point(x=dataTest$selling_price,y=dataTest$notlinearPred2, aes(colour='RETE NEURALE CON WD=0.01')) +
  scale_color_manual(
    name='Modello',
    values=c('black','red')) + geom_abline(col="grey")

```

Dando uno sguardo alle metriche di performance, notiamo che la rete neurale che offre le migliori performance è quella i cui iperparametri sono stati selezionati tramite procedura di cross-validation.

```{r,echo=FALSE, warning=FALSE, message=FALSE}
perf_nn3 <- rbind(round(ComputeMetrics(dataTest$selling_price,dataTest$notlinearPred3),1))

per_dataFrame_nn3 <- as_tibble(perf_nn3)

per_dataFrame_lm_nn <- rbind(per_dataFrame_lm_nn,per_dataFrame_nn3)

rownames(per_dataFrame_lm_nn) <- c("REGRESSIONE LINEARE MULTIPLA", "RETE NEURALE SENZA WD",
                                   "RETE NEURALE CON WD=0.01", "RETE NEURALE RETE NEURALE CON IPERPARAMETRI CV")

per_dataFrame_lm_nn
```

Infine, dando uno sguardo al Q-Q plot e al test di Jarque-Bera, possiamo affermare che i residui della rete neurale migliore non si distribuiscono come una normale.

```{r,echo=FALSE, message=FALSE, warning=FALSE}
residui_test_set_nn3 <- dataTest$selling_price - dataTest$notlinearPred3
qqnorm(residui_test_set_nn3, xlab="Quantili Teorici", ylab="Quantili osservati")  # qq plot dei residui
qqline(residui_test_set_nn3)  # se si aggiunge la retta
```


```{r,echo=FALSE, warning=FALSE, message=FALSE}
## Test di Jarque-Bera
library(tseries)
jarque.bera.test(residui_test_set_nn3)
```


# Libreria ANN2

Per implementare una rete neurale si può utilizzare anche la libreria ANN2. In questo caso la rete neurale è stata implementata considerando i seguenti parametri:

* Numero di neuroni intermedi: 13

* Funzione di attivazione per lo strato nascosto: Sigmoid

* Funzione di attivazione per l'output: Linear

* Funzione di perdita: Squared

* Algoritmo di ottimizzazione per l'aggiornamento dei pesi: Stochastic gradient descent with Momentum con $\gamma$ pari a 0.9

* Learning rates: 0.001

* Regolarizzazione: L2

* Livello di decadimento: 0.9

* Epoche di apprendimento: 1000

Confrontiamo le previsioni della rete neurale implementata con i prezzi di vendita osservati.

```{r,echo=FALSE, message=FALSE, warning=FALSE}
library(ANN2)
set.seed(300399)
ann2_neural_network <- neuralnetwork(
  yxNormalizzate_xCategorialiOneHot_Train2[,-1],
    yxNormalizzate_xCategorialiOneHot_Train2[,1],
  hidden.layers = 13,
  regression = TRUE,
  standardize = FALSE,
  loss.type = "squared",
  activ.functions = "sigmoid",
  optim.type = "sgd",
  learn.rates = 0.001,
  L1 = 0,
  L2 = 1,
  sgd.momentum = 0.9,
  rmsprop.decay = 0.9,
  n.epochs = 1000,
  val.prop = 0.2,
  verbose = FALSE
)
```


```{r}
notlm4.pred <- predict(ann2_neural_network,yxNormalizzate_xCategorialiOneHot_Test2[,-1])

unscale.price <- function(scaled.price){
  unscaled = scaled.price*(max-min) + min
  return(unscaled)
}


notlm4.pred.unscaled <- round(unscale.price(notlm4.pred$predictions),0)

dataTest$notlinearPred4 <- notlm4.pred.unscaled[,1]

ggplot(dataTest,aes(selling_price,notlinearPred4)) +
geom_point() + geom_abline(col="red") + theme_bw() + xlab("Prezzo di vendita") + ylab("Previsione") + ggtitle("Previsione vs Prezzo di vendita") + geom_text(
    x = 40000, y = 22000,
    label = paste("Previsione = Prezzo di vendita"),
    color = "red"
  )
```


Metriche di performance

```{r,echo=FALSE, message=FALSE, warning=FALSE}
perf_not.lm.pred4 <- rbind(round(ComputeMetrics(dataTest$selling_price, dataTest$notlinearPred4),1))

perf_not.lm.pred4 <- as.data.frame(perf_not.lm.pred4)

rownames(perf_not.lm.pred4) <- c("RETE NEURALE CON SGD WITH MOMENTUM")

perf_not.lm.pred4
```







